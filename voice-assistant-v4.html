<!DOCTYPE html>
<html lang="en" class="h-full bg-black">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>J.A.R.V.I.S. Protocol</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;600;700&display=swap" rel="stylesheet">
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: { sans: ['Rajdhani', 'sans-serif'] },
                    colors: { cyan: { 400: '#22d3ee', 500: '#06b6d4', 900: '#164e63' } },
                    animation: {
                        'spin-slow': 'spin 8s linear infinite',
                        'spin-reverse': 'spin-reverse 12s linear infinite',
                    },
                    keyframes: {
                        'spin-reverse': {
                            'from': { transform: 'rotate(360deg)' },
                            'to': { transform: 'rotate(0deg)' },
                        }
                    }
                },
            }
        }
    </script>
    <style>
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: #0f172a; }
        ::-webkit-scrollbar-thumb { background: #06b6d4; border-radius: 3px; }
        .glass-panel {
            background: rgba(8, 51, 68, 0.4);
            backdrop-filter: blur(8px);
            border: 1px solid rgba(34, 211, 238, 0.3);
            box-shadow: 0 0 15px rgba(6, 182, 212, 0.1);
        }
        .hologram-text { text-shadow: 0 0 5px rgba(34, 211, 238, 0.8); }
        .core-ring { border: 2px solid rgba(34, 211, 238, 0.6); border-top-color: transparent; border-bottom-color: transparent; border-radius: 50%; }
        .is-listening .core-center { box-shadow: 0 0 40px #22d3ee; background: #22d3ee; }
        .is-thinking .core-center { box-shadow: 0 0 40px #fbbf24; background: #fbbf24; }
        .is-speaking .core-center { box-shadow: 0 0 40px #a855f7; background: #a855f7; }
        .is-error .core-center { box-shadow: 0 0 40px #ef4444; background: #ef4444; }
    </style>
</head>
<body class="h-full flex flex-col items-center justify-center text-cyan-400 overflow-hidden relative">

    <div class="absolute inset-0 bg-[url('https://grainy-gradients.vercel.app/noise.svg')] opacity-20 pointer-events-none"></div>
    <div class="absolute inset-0" style="background-image: radial-gradient(circle at center, rgba(6,182,212,0.1) 0%, transparent 70%);"></div>

    <div class="relative z-10 w-full max-w-2xl p-8 flex flex-col items-center">
        <!-- Header -->
        <div class="w-full flex justify-between items-end border-b border-cyan-500/30 pb-4 mb-8">
            <div>
                <h1 class="text-5xl font-bold tracking-widest hologram-text">J.A.R.V.I.S.</h1>
                <div class="text-xs tracking-[0.3em] text-cyan-600 mt-1">JUST A RATHER VERY INTELLIGENT SYSTEM</div>
            </div>
            <div class="text-right">
                <div id="status" class="text-xl font-bold animate-pulse">SYSTEM ONLINE</div>
                <div class="text-xs text-cyan-600">V.7.0.0 // CONTINUOUS MODE</div>
            </div>
        </div>

        <!-- Arc Reactor -->
        <div class="relative w-64 h-64 mb-12 flex items-center justify-center">
            <div class="absolute inset-0 border border-cyan-900/50 rounded-full"></div>
            <div class="absolute inset-2 core-ring animate-spin-slow"></div>
            <div class="absolute inset-6 core-ring animate-spin-reverse border-cyan-400/40"></div>
            <div class="absolute inset-10 core-ring animate-spin border-cyan-300/30"></div>
            <div id="core" class="core-center w-20 h-20 bg-cyan-500/20 rounded-full shadow-[0_0_20px_rgba(6,182,212,0.5)] transition-all duration-500 backdrop-blur-md border border-white/20"></div>
        </div>

        <!-- Interaction Area -->
        <div class="w-full space-y-6">
            <div class="glass-panel p-6 rounded-lg min-h-[100px] relative overflow-hidden group">
                <div class="absolute top-0 left-0 w-2 h-2 border-t-2 border-l-2 border-cyan-400"></div>
                <div class="absolute top-0 right-0 w-2 h-2 border-t-2 border-r-2 border-cyan-400"></div>
                <div class="absolute bottom-0 left-0 w-2 h-2 border-b-2 border-l-2 border-cyan-400"></div>
                <div class="absolute bottom-0 right-0 w-2 h-2 border-b-2 border-r-2 border-cyan-400"></div>
                <label class="text-xs text-cyan-600 tracking-widest uppercase mb-2 block">Input Stream</label>
                <div id="sttOutput" class="text-lg text-white/90 font-light leading-relaxed">Ready for command, Sir.</div>
            </div>

            <div class="glass-panel p-6 rounded-lg min-h-[100px] relative overflow-hidden">
                 <label class="text-xs text-cyan-600 tracking-widest uppercase mb-2 block">System Response</label>
                <div id="ttsOutput" class="text-xl text-cyan-300 font-medium leading-relaxed"></div>
            </div>

            <div class="flex justify-center pt-4">
                <button id="listenButton" class="group relative px-8 py-4 bg-cyan-900/30 hover:bg-cyan-500/20 border border-cyan-500/50 rounded pointer-events-auto transition-all duration-300 overflow-hidden">
                    <div class="absolute inset-0 w-0 bg-cyan-500/20 transition-all duration-[250ms] ease-out group-hover:w-full"></div>
                    <span class="relative text-cyan-300 font-bold tracking-widest uppercase group-hover:text-white">Initialize Listening</span>
                </button>
            </div>
        </div>
        <audio id="audioPlayer" style="display:none"></audio>
    </div>

    <script>
        // --- SOUND ENGINE ---
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const SFX = {
            start: () => {
                const osc = audioCtx.createOscillator(); const gain = audioCtx.createGain();
                osc.connect(gain); gain.connect(audioCtx.destination);
                osc.type = 'sine'; osc.frequency.setValueAtTime(200, audioCtx.currentTime); osc.frequency.exponentialRampToValueAtTime(800, audioCtx.currentTime + 0.1);
                gain.gain.setValueAtTime(0.1, audioCtx.currentTime); gain.gain.exponentialRampToValueAtTime(0.01, audioCtx.currentTime + 0.1);
                osc.start(); osc.stop(audioCtx.currentTime + 0.1);
            },
            process: () => {
                const osc = audioCtx.createOscillator(); const gain = audioCtx.createGain();
                osc.connect(gain); gain.connect(audioCtx.destination);
                osc.type = 'square'; osc.frequency.setValueAtTime(1200, audioCtx.currentTime); osc.frequency.linearRampToValueAtTime(600, audioCtx.currentTime + 0.15);
                gain.gain.setValueAtTime(0.05, audioCtx.currentTime); gain.gain.linearRampToValueAtTime(0.01, audioCtx.currentTime + 0.15);
                osc.start(); osc.stop(audioCtx.currentTime + 0.15);
            },
            success: () => {
                const osc = audioCtx.createOscillator(); const gain = audioCtx.createGain();
                osc.connect(gain); gain.connect(audioCtx.destination);
                osc.type = 'sine'; osc.frequency.setValueAtTime(500, audioCtx.currentTime); osc.frequency.setValueAtTime(1000, audioCtx.currentTime + 0.1);
                gain.gain.setValueAtTime(0.05, audioCtx.currentTime); gain.gain.linearRampToValueAtTime(0.01, audioCtx.currentTime + 0.3);
                osc.start(); osc.stop(audioCtx.currentTime + 0.3);
            },
            error: () => {
                const osc = audioCtx.createOscillator(); const gain = audioCtx.createGain();
                osc.connect(gain); gain.connect(audioCtx.destination);
                osc.type = 'sawtooth'; osc.frequency.setValueAtTime(150, audioCtx.currentTime); gain.gain.setValueAtTime(0.1, audioCtx.currentTime);
                osc.start(); osc.stop(audioCtx.currentTime + 0.3);
            }
        };

        const SERVER_URL = 'http://127.0.0.1:5000';
        const listenButton = document.getElementById('listenButton');
        const statusEl = document.getElementById('status');
        const sttOutputEl = document.getElementById('sttOutput');
        const ttsOutputEl = document.getElementById('ttsOutput');
        const audioPlayer = document.getElementById('audioPlayer');
        const body = document.body;

        let mediaRecorder;
        let audioChunks = [];
        let isListening = false;
        let conversationHistory = [];
        let conversationActive = false; // Controls the loop

        // --- DATA FEEDS ---
        async function getEnvironmentalData() {
            updateSystemState('SCANNING ENVIRONMENT...', 'is-thinking');
            return new Promise((resolve) => {
                if (!navigator.geolocation) { resolve("Location sensors offline. Defaulting to sector 7."); return; }
                navigator.geolocation.getCurrentPosition(async (position) => {
                    const lat = position.coords.latitude; const lon = position.coords.longitude;
                    try {
                        const weatherReq = await fetch(`https://api.open-meteo.com/v1/forecast?latitude=${lat}&longitude=${lon}&current=temperature_2m,weather_code&temperature_unit=fahrenheit`);
                        const weatherData = await weatherReq.json();
                        const temp = weatherData.current.temperature_2m;
                        const wCode = weatherData.current.weather_code;
                        const conditions = wCode < 3 ? "clear skies" : wCode < 50 ? "cloudy" : wCode < 80 ? "rainy" : "stormy";
                        const now = new Date();
                        resolve(`Time: ${now.toLocaleTimeString()}. Date: ${now.toDateString()}. Location Coords: ${lat.toFixed(2)}, ${lon.toFixed(2)}. Temperature: ${temp}F. Conditions: ${conditions}. Battery: 100%. Systems: Nominal.`);
                    } catch (e) { resolve("Environmental sensors failing. Unable to retrieve weather data."); }
                }, (err) => { resolve("Location access denied by user protocol."); });
            });
        }

        async function setupAudioRecorder() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.ondataavailable = (event) => audioChunks.push(event.data);
                mediaRecorder.onstop = async () => {
                    SFX.process(); 
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    audioChunks = [];
                    await sendAudioToServer(audioBlob);
                };
            } catch (err) {
                statusEl.textContent = 'MIC OFFLINE';
                SFX.error();
            }
        }

        async function sendAudioToServer(audioBlob) {
            updateSystemState('PROCESSING...', 'is-thinking');
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');

            try {
                const response = await fetch(`${SERVER_URL}/transcribe`, { method: 'POST', body: formData });
                const data = await response.json();
                if (data.error) throw new Error(data.error);
                const transcript = data.transcript;
                sttOutputEl.textContent = `"${transcript}"`;

                if (transcript.trim()) await processCommand(transcript);
                else { 
                    // If silent, don't keep loop running endlessly
                    conversationActive = false;
                    updateSystemState('NO INPUT', ''); 
                    resetButton(); 
                }
            } catch (error) {
                conversationActive = false;
                statusEl.textContent = 'SYSTEM ERROR';
                SFX.error();
                resetButton();
            }
        }

        async function processCommand(text) {
            const command = text.toLowerCase();
            
            // --- EXIT PROTOCOLS ---
            const exitPhrases = ["goodbye", "thanks", "thank you", "dismissed", "that is all", "stop", "quit", "exit", "sleep"];
            if (exitPhrases.some(phrase => command.includes(phrase))) {
                conversationActive = false; // Break the loop
                // We still ask Gemini for a polite goodbye response
            } else {
                conversationActive = true; // Continue the loop
            }

            // --- PROTOCOL: MORNING REPORT ---
            if (command.includes("report") || command.includes("status") || command.includes("briefing")) {
                SFX.process();
                const envData = await getEnvironmentalData();
                await askGemini(envData, "You are J.A.R.V.I.S. The user just asked for a Morning Report. Use the provided raw environmental data to construct a formal, witty, and concise morning briefing for 'Sir'. Do not mention you are an AI. Just give the report.");
                return;
            }

            // Standard Commands
            if (command.includes("open youtube")) { SFX.success(); speakResponse("Opening YouTube."); window.open("https://www.youtube.com", "_blank"); conversationActive = false; return; }
            if (command.includes("open google")) { SFX.success(); speakResponse("Opening Google."); window.open("https://www.google.com", "_blank"); conversationActive = false; return; }
            if (command.includes("wipe memory")) { SFX.process(); conversationHistory = []; speakResponse("Memory flushed."); return; }

            // Standard Conversation
            conversationHistory.push({ role: "user", parts: [{ text: text }] });
            await askGemini(text);
        }

        async function askGemini(text, overrideSystemPrompt = null) {
            // --- PASTE API KEY HERE ---
            const apiKey = "YOUR_GOOGLE_API_KEY_HERE"; 
            // -------------------------
            
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;
            const defaultSystemPrompt = "You are J.A.R.V.I.S. Address user as 'Sir'. Keep responses concise, witty, and spoken-style.";
            
            const payload = {
                contents: overrideSystemPrompt ? [{role: "user", parts: [{text: text}]}] : conversationHistory,
                systemInstruction: { parts: [{ text: overrideSystemPrompt || defaultSystemPrompt }] }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                const answer = result.candidates?.[0]?.content?.parts?.[0]?.text || "Processing error.";
                
                if (!overrideSystemPrompt) conversationHistory.push({ role: "model", parts: [{ text: answer }] });
                
                SFX.success();
                typeWriterEffect(answer, ttsOutputEl);
                await speakResponse(answer);
            } catch (error) {
                console.error(error);
                statusEl.textContent = "NEURAL LINK FAILED";
                SFX.error();
                conversationActive = false;
                resetButton();
            }
        }

        async function speakResponse(text) {
            updateSystemState('VOCALIZING', 'is-speaking');
            try {
                const response = await fetch(`${SERVER_URL}/speak`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });
                if (!response.ok) throw new Error("TTS Failed");
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayer.src = audioUrl;
                audioPlayer.play();
                
                // --- CONTINUOUS LOOP LOGIC ---
                audioPlayer.onended = () => {
                    if (conversationActive) {
                        // If active, restart listening after brief pause
                        updateSystemState('AWAITING INPUT...', 'is-listening');
                        setTimeout(() => {
                             toggleListening();
                        }, 500);
                    } else {
                        // If not active (or exit phrase used), go to idle
                        updateSystemState('SYSTEM ONLINE', '');
                        resetButton();
                    }
                };

            } catch (error) {
                statusEl.textContent = "AUDIO OUTPUT ERROR";
                SFX.error();
                resetButton();
            }
        }

        function updateSystemState(text, cls) {
            statusEl.textContent = text;
            body.classList.remove('is-listening', 'is-thinking', 'is-speaking', 'is-error');
            if (cls) body.classList.add(cls);
        }

        function typeWriterEffect(text, el) {
            el.textContent = ''; let i = 0;
            function type() { if (i < text.length) { el.textContent += text.charAt(i); i++; setTimeout(type, 20); } }
            type();
        }

        function toggleListening() {
            if (audioCtx.state === 'suspended') audioCtx.resume();
            if (!mediaRecorder) return;
            if (isListening) {
                mediaRecorder.stop(); isListening = false; listenButton.disabled = true;
                listenButton.querySelector('span').textContent = 'PROCESSING...';
                body.classList.remove('is-listening');
            } else {
                SFX.start(); isListening = true; sttOutputEl.textContent = '...'; ttsOutputEl.textContent = '';
                updateSystemState('LISTENING...', 'is-listening');
                listenButton.querySelector('span').textContent = 'STOP INPUT';
                mediaRecorder.start();
            }
        }

        function resetButton() {
            isListening = false; listenButton.disabled = false;
            body.classList.remove('is-listening', 'is-thinking', 'is-speaking', 'is-error');
            listenButton.querySelector('span').textContent = 'INITIALIZE LISTENING';
        }

        listenButton.addEventListener('click', toggleListening);
        setupAudioRecorder();
    </script>
</body>
</html>